<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="原子态"><meta name="copyright" content="原子态"><meta name="generator" content="Hexo 4.2.1"><meta name="theme" content="hexo-theme-yun"><title>【搞定神经网络】循环神经网络篇 | 原子态</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;family=Source+Code+Pro&amp;display=swap" media="none" onload="this.media='all'"><script src="//at.alicdn.com/t/font_1140697_stqaphw3j4.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});
</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://cdn.jsdelivr.net/gh/atomicoo/hexo-theme-yun@latest/source/js/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script><link rel="shortcut icon" type="image/svg+xml" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="stylesheet" href="/css/hexo-theme-yun.css"><link rel="alternate" href="/atom.xml" title="原子态"><script id="yun-config">
    const Yun = window.Yun || {};
    window.CONFIG = {"root":"/","title":"一行代码调一天","version":"0.9.1","anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"algolia":{"appID":"KP7IPEQ96T","apiKey":"4d1c9fc1470aaacb209d4eecaf3b4879","indexName":"my-hexo-blog","hits":{"per_page":8},"labels":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容: ${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};
  </script><link rel="preconnect" href="https://www.google-analytics.com" crossorigin><link rel="preconnect" href="https://stats.g.doubleclick.net" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=UA-170889853-1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-170889853-1');</script><meta name="description" content="引言【搞定神经网络系列】博客开坑第一篇，循环神经网络篇。 循环神经网络（Recurrent Neural Network, RNN）是一类人工神经网络，通常以序列（sequence）数据为输入，在序列的演进方向进行递归（recursion）且所有节点（循环单元）按链式连接。需要注意的是循环神经网络具有记忆性且参数共享。">
<meta property="og:type" content="article">
<meta property="og:title" content="【搞定神经网络】循环神经网络篇">
<meta property="og:url" content="https://atomicoo.com/mathematics/understanding-rnn-networks/index.html">
<meta property="og:site_name" content="原子态">
<meta property="og:description" content="引言【搞定神经网络系列】博客开坑第一篇，循环神经网络篇。 循环神经网络（Recurrent Neural Network, RNN）是一类人工神经网络，通常以序列（sequence）数据为输入，在序列的演进方向进行递归（recursion）且所有节点（循环单元）按链式连接。需要注意的是循环神经网络具有记忆性且参数共享。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/07/23/GZcjyeQiAWLsNaX.png">
<meta property="og:image" content="https://i.loli.net/2020/07/23/3AdiHYOaXCqTzw8.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/FPe4EL9rbmwizVG.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/GIm9ilRwsjEaOgS.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/8YSrXD74nuL2iVT.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/ndczrI1UkKu9BoA.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/CtQHRNah2bYGIVk.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/9cHTfi1PgjZAsJG.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/Ofw8mvycq9pFSH7.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/wvOMDegrj1idyNG.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/TvKPbklNqOdjw9L.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/ecyrjV6iN2OvpgH.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/Y8yXdcvHnqGmbgN.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/28VcwqbzKu5lE9L.png">
<meta property="og:image" content="https://i.loli.net/2020/08/07/35ldwRJIc6sEoQm.png">
<meta property="article:published_time" content="2020-07-14T08:15:48.000Z">
<meta property="article:modified_time" content="2020-07-14T08:15:48.000Z">
<meta property="article:author" content="原子态">
<meta property="article:tag" content="RNN">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="LSTM">
<meta property="article:tag" content="GRU">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/07/23/GZcjyeQiAWLsNaX.png"><script src="/js/ui/mode.js"></script><link rel="alternate" href="/atom.xml" title="原子态" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script defer src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="原子态"><img width="96" loading="lazy" src="/images/avatar.jpg" alt="原子态"></a><div class="site-author-name"><a href="/about/">原子态</a></div><a class="site-name" href="/about/site.html">原子态</a><sub class="site-subtitle">Atomicoo's</sub><div class="site-desciption">“咚！咚！咚！”</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">13</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">5</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">24</span></a></div><a class="site-state-item hty-icon-button" href="/about/#comment" title="留言板"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-clipboard-line"></use></svg></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/atomicoo" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/409646386" title="哔哩哔哩" target="_blank" style="color:#FF8EB3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:atomicoo95@gmail.com" title="E-Mail" target="_blank" style="color:#8E71C1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="Links" style="color:dodgerblue"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a><a class="links-item hty-icon-button" href="/girls/" title="Girls" style="color:hotpink"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-women-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color: #f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络基础"><span class="toc-number">2.</span> <span class="toc-text">神经网络基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#循环神经网络"><span class="toc-number">3.</span> <span class="toc-text">循环神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#长短时记忆网络"><span class="toc-number">4.</span> <span class="toc-text">长短时记忆网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM-逐步分解"><span class="toc-number">5.</span> <span class="toc-text">LSTM 逐步分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM-的变体"><span class="toc-number">6.</span> <span class="toc-text">LSTM 的变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多层-RNN-结构"><span class="toc-number">7.</span> <span class="toc-text">多层 RNN 结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#双向-RNN-结构"><span class="toc-number">8.</span> <span class="toc-text">双向 RNN 结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-number">9.</span> <span class="toc-text">参考资料</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://atomicoo.com/mathematics/understanding-rnn-networks/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="原子态"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="原子态"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">【搞定神经网络】循环神经网络篇<a class="post-edit-link" href="https://github.com/atomicoo/atomicoo.github.io/tree/source/source/_posts/mathematics/understanding-rnn-networks.md" target="_blank" title="编辑" rel="noopener"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-edit-line"></use></svg></a></h1><div class="post-meta"><div class="post-time" style="display:block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span> <time title="创建时间：2020-07-14 16:15:48" itemprop="dateCreated datePublished" datetime="2020-07-14T16:15:48+08:00">2020-07-14</time></div><span class="post-count"><span class="post-symbolcount"><span class="post-meta-item-icon" title="本文字数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-file-word-line"></use></svg></span> <span title="本文字数">5.8k</span><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读时长"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-timer-line"></use></svg></span> <span title="阅读时长">11 分钟</span></span></span><span class="leancloud_visitors" id="/mathematics/understanding-rnn-networks/" data-flag-title="【搞定神经网络】循环神经网络篇"><span class="post-meta-divider">-</span><span class="post-meta-item-icon" title="阅读次数"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-eye-line"></use></svg> <span class="leancloud-visitors-count"></span></span></span><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span> <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/%E6%95%B0%E5%AD%A6%E7%A0%94%E7%A9%B6/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">数学研究</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category" href="/categories/%E6%95%B0%E5%AD%A6%E7%A0%94%E7%A9%B6/%E4%BF%A1%E6%81%AF%E6%97%B6%E4%BB%A3/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">信息时代</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag" href="/tags/RNN/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">RNN</span></a><a class="tag" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">神经网络</span></a><a class="tag" href="/tags/LSTM/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">LSTM</span></a><a class="tag" href="/tags/GRU/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">GRU</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content post-markdown"><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>【搞定神经网络系列】博客开坑第一篇，循环神经网络篇。</p>
<p>循环神经网络（Recurrent Neural Network, RNN）是一类人工神经网络，通常以序列（sequence）数据为输入，在序列的演进方向进行递归（recursion）且所有节点（循环单元）按链式连接。需要注意的是循环神经网络具有记忆性且参数共享。</p>
<a id="more"></a>

<h2 id="神经网络基础"><a href="#神经网络基础" class="headerlink" title="神经网络基础"></a>神经网络基础</h2><p>要了解递归神经网络，首先就得了解神经网络。</p>
<p>那么，什么是神经网络呢？你可以将神经网络简单地看成是一个<strong>黑盒子</strong>，里面装了一大堆的可训练参数，参数与参数的组织形式共同构成了所谓的“<strong>模型</strong>”，这个模型建模了具有实际意义的一项或几项任务，当你手头拥有与任务相对应的数据时，你就可以使用你的数据训练这些参数来拟合真实的模型（上帝的模型？除了上帝，没人知道真实的模型是啥样的，只能通过已有的数据进行拟合）。</p>
<blockquote>
<p>当然，要训练一个神经网络，除了模型本身之外，还需要有<strong>优化器</strong>和<strong>损失函数</strong>（这就是另外的话题了）。</p>
</blockquote>
<p>既然说参数与参数的组织形式共同构成了模型，那么我们自然可以通过改变参数及其组织形式来构造出各种不同的（神经网络）模型，本博客介绍的就是其中的循环神经网络。</p>
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>考虑平时阅读文章时的情景，显然你并不是将文章的每个字/词当成一个个完全独立的单元来进行阅读的，你在阅读每个字/词时都会考虑前文内容（甚至预想后文内容），也就是说，在处理类似于文本/语音这类序列数据时，我们的模型需要具备获取上下文信息的能力，传统的神经网络结构显然对此无能为力，然鹅，循环神经网络解决了这一问题。</p>
<p>循环神经网络，顾名思义，具有循环结构的神经网络，它（理论上）可以持续保存上下文信息，其结构如下图：</p>
<p><img src="https://i.loli.net/2020/07/23/GZcjyeQiAWLsNaX.png" alt="RNN.png" loading="lazy"></p>
<p>看起来貌似有那么一丢丢的复杂，那么我们将循环展开来看看：</p>
<p><img src="https://i.loli.net/2020/07/23/3AdiHYOaXCqTzw8.png" alt="RNN-.png" loading="lazy"></p>
<p>Emmm，结构清晰多了，可以看到前文信息确实是可以随着循环一层一层地往后传递的。</p>
<blockquote>
<p>需要注意的是，在单向 RNN 中，模型只能向后传递前文信息，若要同时考虑上下文的信息则应使用双向 RNN，关于双向 RNN 的内容后面也会提到。</p>
</blockquote>
<p>事实上这个结构应该叫做简单循环网络（simple recurrent network，SRN），又称为 Elman Network，是由 Jeff Elman 在 1990 年提出的，在 Jordan Network（1986）的基础上进行了改进并简化了结构。关于两者的区别这里不做赘述。</p>
<p>Notes：前文提到，循环神经网络通常用于处理序列数据，因此，在进一步介绍循环神经网络之前，我想在这儿丢张图，列举出序列数据处理任务可能的几种形式，具体就不多 BB 了，很容易看懂。</p>
<p><img src="https://i.loli.net/2020/08/07/FPe4EL9rbmwizVG.png" alt="seq2seq.png" loading="lazy"></p>
<h2 id="长短时记忆网络"><a href="#长短时记忆网络" class="headerlink" title="长短时记忆网络"></a>长短时记忆网络</h2><p>上一节已经介绍了循环神经网络的基本结构，但是循环结构中的重复单元（可以类比于编程中的循环体）是啥呢？</p>
<p>在具体说明之前，我们需要提前定义几个操作的表示方式：</p>
<p><img src="https://i.loli.net/2020/08/07/GIm9ilRwsjEaOgS.png" alt="operation.png" loading="lazy"></p>
<p>定义操作完毕，我们圆规正转（<del>谐音梗扣钱</del>），继续来讨论重复单元的问题。显而易见，根据重复单元的不同，可以定义出完全不同类型的循环神经网络。</p>
<p>事实上，标准 RNN 中的重复单元具有非常简单的结构，就是一个单层的神经网络。</p>
<p><img src="https://i.loli.net/2020/08/07/8YSrXD74nuL2iVT.png" alt="rnn.png" loading="lazy"></p>
<p>具体公式如下：</p>
<p>$$ h_{t}=g(W \cdot [x_{t}, h_{t-1}]+b) $$</p>
<p>其中，$g(\cdot)$ 为激活函数，通常选择 $sigmoid(\cdot)$ 或 $tanh(\cdot)$。</p>
<p>很遗憾的一点是，尽管 RNN 的结构在理论上具备获取足够的上下文信息的能力，但在实践中似乎不是这样的，标准 RNN 在实际表现中并不尽如人意，尤其是随着序列的上下文信息的跨度变大，标准 RNN  开始无法学习相应的信息。</p>
<p>幸运的是，后续衍生出的 LSTM 较好地解决了这个问题。</p>
<p><img src="https://i.loli.net/2020/08/07/ndczrI1UkKu9BoA.png" alt="lstm.png" loading="lazy"></p>
<p>LSTM 的关键点在于 Cell State，也就是如下图所示，贯穿了整个“循环”过程的 $C$。</p>
<p><img src="https://i.loli.net/2020/08/07/CtQHRNah2bYGIVk.png" alt="cell.png" loading="lazy"></p>
<p>这其实有点像是传送带，cell state 会沿着这条传送带逐层往后传送，在传送过程中不断有旧的状态被删除、新的状态被添加，而对状态信息的增删进行控制的部分就是其中门的机制。具体的（控制）操作方式就是逐元素乘法（pointwise multiplication operation）。</p>
<p><img src="https://i.loli.net/2020/08/07/9cHTfi1PgjZAsJG.png" alt="gated.png" loading="lazy"></p>
<h2 id="LSTM-逐步分解"><a href="#LSTM-逐步分解" class="headerlink" title="LSTM 逐步分解"></a>LSTM 逐步分解</h2><p>遗忘门（forget gate）控制有哪些旧的信息会被删除。</p>
<p><img src="https://i.loli.net/2020/08/07/Ofw8mvycq9pFSH7.png" alt="lstm-forget.png" loading="lazy"></p>
<p>输入门（input gate）控制有哪些新的信息会被添加。</p>
<p><img src="https://i.loli.net/2020/08/07/wvOMDegrj1idyNG.png" alt="lstm-input.png" loading="lazy"></p>
<p>旧的状态信息经过遗忘门和输入门对信息的增删之后，得到新的状态信息（cell state）。</p>
<p><img src="https://i.loli.net/2020/08/07/TvKPbklNqOdjw9L.png" alt="lstm-cell.png" loading="lazy"></p>
<p>输出门（output gate）控制最终有哪些信息会被输出。</p>
<p><img src="https://i.loli.net/2020/08/07/ecyrjV6iN2OvpgH.png" alt="lstm-output.png" loading="lazy"></p>
<h2 id="LSTM-的变体"><a href="#LSTM-的变体" class="headerlink" title="LSTM 的变体"></a>LSTM 的变体</h2><p>窥孔连接：</p>
<p><img src="https://i.loli.net/2020/08/07/Y8yXdcvHnqGmbgN.png" alt="lstm-var1.png" loading="lazy"></p>
<p>耦合遗忘/输入门：</p>
<p><img src="https://i.loli.net/2020/08/07/28VcwqbzKu5lE9L.png" alt="lstm-var2.png" loading="lazy"></p>
<p>GRU（Gated Recurrent Unit）将遗忘/输入门合并为更新门（update gate），并合并了 cell state 与 hidden state。</p>
<p><img src="https://i.loli.net/2020/08/07/35ldwRJIc6sEoQm.png" alt="gru.png" loading="lazy"></p>
<p>需要注意的是，以上这几种类型（包括标准的 LSTM）各擅胜场，并没有明确的优劣势，在具体的任务中选择哪种类型通常需要通过实验来确定。</p>
<h2 id="多层-RNN-结构"><a href="#多层-RNN-结构" class="headerlink" title="多层 RNN 结构"></a>多层 RNN 结构</h2><p>（空）</p>
<h2 id="双向-RNN-结构"><a href="#双向-RNN-结构" class="headerlink" title="双向 RNN 结构"></a>双向 RNN 结构</h2><p>（空）</p>
<hr>
<p>To Be Continued.</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></p>
<p><a href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory" target="_blank" rel="noopener">long short-term memory (LSTM)</a></p>
<p><a href="https://arxiv.org/abs/1409.1259" target="_blank" rel="noopener">gated recurrent units (GRU)</a></p>
<!-- Q.E.D. --><script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script></div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">此路是我开，留下买路财 [ 狗头 ]</div><div id="qr" style="display:none;"><div style="display:inline-block"><a href="/images/alipay.jpg"><img loading="lazy" src="/images/alipay.jpg" alt="支付宝" title="支付宝"></a><div><span style="color:#00A3EE"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/images/qq-pay.jpg"><img loading="lazy" src="/images/qq-pay.jpg" alt="QQ 支付" title="QQ 支付"></a><div><span style="color:#12B7F5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></span></div></div><div style="display:inline-block"><a href="/images/wechat-pay.jpg"><img loading="lazy" src="/images/wechat-pay.jpg" alt="微信支付" title="微信支付"></a><div><span style="color:#2DC100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>原子态</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://atomicoo.com/mathematics/understanding-rnn-networks/" title="【搞定神经网络】循环神经网络篇">https://atomicoo.com/mathematics/understanding-rnn-networks/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a> 许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/mathematics/understanding-language-model/" rel="prev" title="理解语言模型 Language Model"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">理解语言模型 Language Model</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/info-science/torch-nn-Module-source-code/" rel="next" title="【PyTorch 源码阅读】 torch.nn.Module 篇"><span class="post-nav-text">【PyTorch 源码阅读】 torch.nn.Module 篇</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div id="comment"><div class="comment-tooltip text-center"><span>重要评论建议跳转 GitHub Issues 发布</span><br><span>每篇文章的首个评论需要先根据 Comment 模板创建相应的 Issue</span><br><span>请避免创建重复的 Issue，感谢配合</span><br><a class="hty-button hty-button--raised" id="github-issues" href="https://github.com/atomicoo/atomicoo.github.io/issues?q=is:issue+【搞定神经网络】循环神经网络篇" target="_blank" rel="noopener">GitHub Issues</a></div><div id="valine-container"></div><script src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script>function initValine() {
  const valineConfig = {"enable":true,"appId":"frjzlYEWNDPLkxagtOz0FWFe-9Nh9j0Va","appKey":"gK2710zgTWTS3C6UchnWhQHd","placeholder":"大佬们缺捡肥皂的吗？_(:з」∠)_","visitor":true,"recordIP":true,"enableQQ":true,"requiredFields":["nick","mail"],"avatar":null,"pageSize":10,"highlight":true,"el":"#valine-container","lang":"zh-cn"}
  valineConfig.path = window.location.pathname
  new Valine(valineConfig)
}
setTimeout(initValine, 1000)</script></div></main><footer class="sidebar-translate" id="footer"><div class="beian"><a rel="noopener" href="http://www.beian.miit.gov.cn" target="_blank">闽ICP备20015372号</a></div><div class="copyright"><span>&copy; 2020 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author"> 原子态</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v4.2.1</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v0.9.1</span></div></footer><a class="hty-icon-button" id="goUp" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" href="javascript:;" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a><script>window.addEventListener("DOMContentLoaded", () => {
  // Handle and trigger popup window
  document.querySelector(".popup-trigger").addEventListener("click", () => {
    document.querySelector(".popup").classList.add("show");
    setTimeout(() => {
      document.querySelector(".search-input").focus();
    }, 100);
  });

  // Monitor main search box
  const onPopupClose = () => {
    document.querySelector(".popup").classList.remove("show");
  };

  document.querySelector(".popup-btn-close").addEventListener("click", () => {
    onPopupClose();
  });

  window.addEventListener("keyup", event => {
    if (event.key === "Escape") {
      onPopupClose();
    }
  });
});
</script><script defer src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script defer src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script defer src="/js/search/algolia-search.js"></script><div class="popup search-popup"><div class="search-header"><span class="popup-btn-close close-icon hty-icon-button"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-close-line"></use></svg></span></div><div class="search-input-container"></div><div class="algolia-results"><div id="algolia-stats"></div><div id="algolia-hits"></div><div class="algolia-pagination" id="algolia-pagination"></div></div></div></div><script defer src="/js/utils.js"></script><script defer src="/js/hexo-theme-yun.js"></script></body></html>